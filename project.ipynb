{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd004ee5f47cd1c657bf4a7c7634c74bb2fba1408c167e1cd3d93a74d411f89979a",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R^2: 0.9093642148392331\n",
      "mse: 46.54548365437432\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "#import data\n",
    "df = pd.read_csv('data/data.csv')\n",
    "\n",
    "def mse(model, x, y):\n",
    "    '''Mean Square Error'''\n",
    "    return np.mean((y - model.predict(x))**2)\n",
    "\n",
    "#set x and y, drop columns\n",
    "y = df.number_people\n",
    "x = df.drop(columns=['number_people', 'date', 'month', 'is_start_of_semester', 'timestamp', 'is_weekend', 'is_holiday'])\n",
    "\n",
    "#Train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, shuffle=True, train_size=0.7, random_state=0)\n",
    "\n",
    "#Scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = pd.DataFrame(scaler.transform(x_train), index=x_train.index, columns=x_train.columns)\n",
    "x_test = pd.DataFrame(scaler.transform(x_test), index=x_test.index, columns=x_test.columns)\n",
    "\n",
    "#Model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print('R^2:', model.score(x_test, y_test))\n",
    "print('mse:', mse(model, x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. We felt that finding the perfect time to go to the gym (AKA when is the gym the most empty) is a very relatable problem\n",
    "#this data set had a lot of different data types and collection points\n",
    "#2. At first we took out the columns that we thought wouldn't make the biggest difference or was repetitive data.\n",
    "#'temperature', 'is during semester', 'hour', etc.\n",
    "#We then played around with the different columns a lot to find which ones were predictors and found that 'hour', 'temperature', 'day of week', and 'is during semester' are the strongest\n",
    "#'hour' and 'temperature' are the strongest and 'is during the semester' was the weakest of those\n",
    "#3. We used RandomForestRegressor as our main model after shuffling and splitting our data into test and train sections\n",
    "#we also used StandardScaler to make our data scale similarly because 'hour' and 'temperature' dont have the same scale\n",
    "#4. Pipeline didn't work for us in this particular scenario\n",
    "#Ridge and Linearregression just wasn't as effective as the RandomForestRegressor\n",
    "#KFold was abandoned for train/test split\n",
    "#5. Apparently, 'temperature' was a stronger predictor than 'time of day' which doesn't make sense\n",
    "#'hour' is also a stronger predictor than 'timestamp' even though they scale the same way\n",
    "#'timestamp' is strongest predictor by itself but 'timestamp' with 'temperature' was not as strong as 'hour' and 'temperature' together"
   ]
  }
 ]
}